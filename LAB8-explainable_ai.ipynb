{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### eXplainable AI - XAI\n",
        "- XAI (Explainable AI): answers \"why did the model make this specific prediction?\"\n",
        "- Supports better decision-making by revealing influential factors.\n",
        "- Improves trust in the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LIME\n",
        "- Builds a simple model around that instance to approximate behavior\n",
        "- Slightly changes inputs → sees how outputs change → finds key features\n",
        "- Shows which features mattered most for that prediction\n",
        "- Highlights magnitude & direction of each feature\n",
        "- Practical for human-understandable explanations of feature influence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# 1. Load and prepare dataset (Car Price Prediction)\n",
        "df = pd.read_csv('primary_features_boolean_converted_final.csv')\n",
        "df = df.dropna(subset=['price(Georgian Lari)'])  # Remove rows with missing target\n",
        "\n",
        "# Feature engineering - create meaningful features for regression\n",
        "df['vehicle_age'] = 2024 - df['product_year']  # Age affects value and condition\n",
        "df['luxury_score'] = df[['engine_volume', 'cylinders', 'airbags']].sum(axis=1)  # Luxury indicators\n",
        "df['safety_score'] = df[['airbags', 'ABS', 'ESP', 'Central Locking', 'Alarm System']].sum(axis=1)  # Safety features\n",
        "\n",
        "# Select numerical features for regression\n",
        "numerical_features = ['vehicle_age', 'luxury_score', 'safety_score', 'mileage', 'engine_volume']\n",
        "X = df[numerical_features].fillna(0)  # Fill missing values with 0\n",
        "y = df['price(Georgian Lari)']  # Target: continuous price\n",
        "\n",
        "feature_names = numerical_features\n",
        "\n",
        "# Take only 1000 random samples for faster computation\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(len(X), min(1000, len(X)), replace=False)\n",
        "X = X.iloc[indices] if isinstance(X, pd.DataFrame) else X[indices]\n",
        "y = y.iloc[indices] if isinstance(y, pd.Series) else y[indices]\n",
        "\n",
        "# Convert to numpy arrays for compatibility\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# 2. Train a regression model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Initialize LIME explainer\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=X_train,\n",
        "    feature_names=feature_names,\n",
        "    mode=\"regression\"\n",
        ")\n",
        "\n",
        "# 4. Pick a test instance\n",
        "i = 6\n",
        "exp = explainer.explain_instance(\n",
        "    data_row=X_test[i],\n",
        "    predict_fn=model.predict\n",
        ")\n",
        "\n",
        "# 5. Get explanation as table\n",
        "explanation_list = exp.as_list()\n",
        "df_explanation = pd.DataFrame(explanation_list, columns=[\"Feature\", \"Contribution\"])\n",
        "\n",
        "print(\"True value:\", y_test[i])\n",
        "print(\"Predicted value:\", model.predict([X_test[i]])[0])\n",
        "print(df_explanation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SHAP\n",
        "- Explains predictions by assigning each feature a contribution value\n",
        "- Based on Shapley values from cooperative game theory. Fairly distribute the \"payout\" (prediction) among all features\n",
        "- Provides both local explanations for individual predictions and global explanations through aggregated feature importance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shap\n",
        "shap.initjs()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a SHAP explainer:\n",
        "# This object calculates Shapley values, which show how much each feature\n",
        "# contributes to the model's predictions. It works with the trained model,\n",
        "# uses X_test as background data, and labels outputs with feature_names.\n",
        "# This sets up the explainer object. Think of it as \"preparing the tool\" that knows how to compute SHAP values for your model.\n",
        "shap_explainer = shap.Explainer(model.predict, X_test, feature_names=feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate SHAP values for the test set:\n",
        "# Each value shows how much a feature contributes (positively or negatively)\n",
        "# to the model's prediction for each instance in X_test.\n",
        "# This actually runs the explainer on your test data. It outputs the SHAP values (numbers that tell you each feature's contribution).\n",
        "shap_values = shap_explainer(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_instance_index = 4\n",
        "shap_values[test_instance_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- SHAP values → feature contributions for each instance.\n",
        "- Base value → the model's average prediction (baseline).\n",
        "- Data → the actual input samples used (here, rows from X_test).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.text as mtext\n",
        "import matplotlib\n",
        "\n",
        "# Get the Axes object\n",
        "ax = shap.plots.waterfall(shap_values[test_instance_index], show=False)\n",
        "\n",
        "# Get the figure from the axes\n",
        "fig = ax.figure\n",
        "\n",
        "# Resize the figure\n",
        "fig.set_size_inches(10, 6)\n",
        "\n",
        "for ax in fig.axes:\n",
        "    for child in ax.get_children():\n",
        "        if isinstance(child, mtext.Text):\n",
        "            #child.set_fontsize(10)         # Font size\n",
        "            child.set_fontfamily('Calibri')  # Font family\n",
        "            child.set_color('black')    # Font color\n",
        "\n",
        "    # Optional: update axis tick labels\n",
        "    ax.tick_params(axis='both', labelsize=12, colors='black')\n",
        "    ax.set_title(\"SHAP explanation for Car Price Prediction\", fontsize=12, fontfamily='Cambria', color='black')\n",
        "    #ax.set_title(\"SHAP explanation for test instance 02\", fontsize=5, fontfamily='Cambria', color='black')\n",
        "\n",
        "# Show the resized figure\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test[test_instance_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Baseline car price: The model's average prediction\n",
        "- Feature contributions: Each feature's SHAP value shows how much it increases or decreases the predicted price\n",
        "- Final prediction = base_value + sum(SHAP values)\n",
        "- Positive SHAP values → increase predicted price\n",
        "- Negative SHAP values → decrease predicted price\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# 1. Load and prepare dataset (Car Price Categories for Classification)\n",
        "df_cls = pd.read_csv('primary_features_boolean_converted_final.csv')\n",
        "df_cls = df_cls.dropna(subset=['price(Georgian Lari)'])  # Remove rows with missing target\n",
        "\n",
        "# Feature engineering - create meaningful features for classification\n",
        "df_cls['vehicle_age'] = 2024 - df_cls['product_year']  # Age affects value and condition\n",
        "df_cls['luxury_score'] = df_cls[['engine_volume', 'cylinders', 'airbags']].sum(axis=1)  # Luxury indicators\n",
        "df_cls['safety_score'] = df_cls[['airbags', 'ABS', 'ESP', 'Central Locking', 'Alarm System']].sum(axis=1)  # Safety features\n",
        "\n",
        "# Create target variable for classification - use quantile-based binning\n",
        "price_data = df_cls['price(Georgian Lari)']\n",
        "q33 = price_data.quantile(0.33)\n",
        "q67 = price_data.quantile(0.67)\n",
        "\n",
        "# Create 3 bins if possible, otherwise 2 bins\n",
        "unique_values = sorted(list(set([price_data.min(), q33, q67, price_data.max()])))\n",
        "if len(unique_values) >= 4 and q33 < q67:\n",
        "    try:\n",
        "        bins = [price_data.min(), q33, q67, price_data.max()]\n",
        "        df_cls['price_category'] = pd.cut(price_data, bins=bins, labels=[0, 1, 2], include_lowest=True)\n",
        "    except Exception as e:\n",
        "        median_price = price_data.median()\n",
        "        df_cls['price_category'] = (price_data > median_price).astype(int)\n",
        "else:\n",
        "    median_price = price_data.median()\n",
        "    df_cls['price_category'] = (price_data > median_price).astype(int)\n",
        "\n",
        "df_cls = df_cls.dropna(subset=['price_category'])\n",
        "\n",
        "# Select numerical features for classification\n",
        "numerical_features_cls = ['vehicle_age', 'luxury_score', 'safety_score', 'mileage', 'engine_volume']\n",
        "X_cls = df_cls[numerical_features_cls].fillna(0)  # Fill missing values with 0\n",
        "y_cls = df_cls['price_category'].astype(int)  # Target: categorical price\n",
        "\n",
        "feature_names_cls = numerical_features_cls\n",
        "\n",
        "# Take only 1000 random samples for faster computation\n",
        "np.random.seed(42)\n",
        "indices_cls = np.random.choice(len(X_cls), min(1000, len(X_cls)), replace=False)\n",
        "X_cls = X_cls.iloc[indices_cls] if isinstance(X_cls, pd.DataFrame) else X_cls[indices_cls]\n",
        "y_cls = y_cls.iloc[indices_cls] if isinstance(y_cls, pd.Series) else y_cls[indices_cls]\n",
        "\n",
        "# Convert to numpy arrays for compatibility\n",
        "X_cls = np.array(X_cls)\n",
        "y_cls = np.array(y_cls)\n",
        "\n",
        "# Get class names\n",
        "unique_classes = np.unique(y_cls)\n",
        "class_names = [f'Price Category {i}' for i in unique_classes]\n",
        "\n",
        "# 2. Train a model\n",
        "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n",
        "model_cls = RandomForestClassifier(n_estimators=500, random_state=42)\n",
        "model_cls.fit(X_train_cls, y_train_cls)\n",
        "\n",
        "# 3. Initialize LIME explainer\n",
        "explainer_cls = LimeTabularExplainer(\n",
        "    training_data=X_train_cls,\n",
        "    feature_names=feature_names_cls,\n",
        "    class_names=class_names,\n",
        "    mode=\"classification\"\n",
        ")\n",
        "\n",
        "# 4. Pick a test instance to explain\n",
        "i = 10\n",
        "exp_cls = explainer_cls.explain_instance(\n",
        "    data_row=X_test_cls[i],\n",
        "    predict_fn=model_cls.predict_proba\n",
        ")\n",
        "\n",
        "# 5. Show explanation\n",
        "print(\"True class:\", class_names[y_test_cls[i]])\n",
        "print(\"Predicted class:\", class_names[model_cls.predict([X_test_cls[i]])[0]])\n",
        "explanation_list_cls = exp_cls.as_list()\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_explanation_cls = pd.DataFrame(explanation_list_cls, columns=[\"Feature\", \"Contribution\"])\n",
        "\n",
        "print(df_explanation_cls)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
